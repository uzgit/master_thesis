% Drones have become a more and more widely used piece of technology in recent years, with their applications ranging from cost-effective aerial imagery, aerial hyperspectral imagery, mapping, real estate surveying, search and rescue, package delivery, and many more. Even more recently, there has been a trend towards \textit{autonomous} drones. Several companies have proprietary navigation systems and flight controllers - for example, DJI's Naza series - which perform well and are widely used, but are black boxes to the public. Some open-source navigation systems and hardware stacks have also been designed - such as ArduPilot and PX4 - which are in widespread usage in the context of recreational, commercial, and industrial drones. Their open source nature intrinsically means that these navigation software systems receive contributions from the drone community, especially in testing and development.

Autonomous drone landing is risky. The sensitive maneuvers and high navigational accuracy required for landing make this a task prone to crashes. As a consequence, robust solutions for autonomous drone landing are typically unavailable in the open source community, while robust, autonomous, open source solutions already exist for takeoff, waypoint-to-waypoint flight, and even other tasks such as photography and videography. Ultimately this means that landing is the main factor that precludes fully autonomous drone missions in most cases. The goal of this project is therefore to develop a robust solution to the problem of autonomous drone landing, which is supported by current, reliable software and technology, and can be easily integrated into existing drone systems.

Current landing solutions are primitive. One such solution, called \texttt{precision\_land} \cite{precision_land_website}, exists in the open source autopilot software \textit{ArduPilot}. This method localizes the landing platform using only its x and y positions in the frame of a camera mounted in a fixed position, usually in line with the downward normal vector to the drone's body. It then attempts to maintain a constant rate of descent until it detects that it can no longer descend, at which point the drone is considered to have landed. This setup has multiple drawbacks. First, the downward-facing camera limits the field of view wherein the landing platform can be recognized. Furthermore, since the positional control of the drone is inherently based on the drone's attitude, positional changes (and inherent attitude changes) can also obfuscate the landing platform from the camera's field of view. Second, the primitive descent policy of simply maintaining constant downward velocity is not ideal. It would be preferable to base the descent rate on the altitude of the drone above the landing platform to allow for a quick, initial approach and slow, smooth contact with the landing platform. Additional tools such as LIDAR or infrared sensors can add this functionality, but they also complicate the system and require more power, communication, and calibration. Third, the fixed, downward-facing camera can often mean that the landing platform is too large to be identified when the drone is extremely close to landing platform, as it will not be contained entirely within the camera's field of view. A typical workaround is to assume that the drone is oriented correctly, and to blindly commit to a landing during this final, crucial stage. This method is inherently dangerous, as even slight errors or wind can cause fatal crashes. Fourth, the landing is controlled using only 2 components of the drone's positional displacement from the landing platform. This means that additional alignment of the drone to the landing platform's yaw orientation, for example, is impossible. Another primitive, autonomous landing solution is simply to navigate to a given waypoint using \gls{GPS} and to maintain the given latitude and longitude coordinates while descending to the ground. This is feasible only in environments that are conducive to very strong, reliable \gls{GPS} signal - such as an open field on a clear day. In less ideal environments - such as urban canyons, mountain valleys, or even open fields on a cloudy day - \gls{GPS} alone cannot provide the required accuracy to land on a small platform, as typical \gls{GPS} position estimates can sometimes vary from reality by as much as 3 meters \cite{accurate_landing_UAV_ground_pattern}.
% Many of the functions of drone flight, such as takeoff, waypoint-to-waypoint navigation, carrying out tasks at specific waypoints, and even flight planning can be easily automated. One particular function is more difficult to automate, however - landing. Drone navigation systems generally depend on \gls{GPS} as a primary localization mechanism, and this can be a problem when landing in areas that are not conducive to strong, reliable GPS signal. Common such scenarios include mountain valleys, metropolitan areas with tall buildings, forests, and even open fields on particularly cloudy days. Therefore, the main goal of this thesis is to develop a landing system for multi-rotor drones that does not depend on \gls{GPS}. Further, the landing system should allow a drone to land on a small moving platform because, in many situations a drone may need to land on a moving target such as a ship or boat. Another aspect of autonomous landing that has not yet been widely implemented is the ability to determine whether a landing should be aborted because of unsafe conditions such as a sudden gust of wind that pushes the drone off track, or inaccurate navigation to the landing site. This system aims to provide a solution to this problem as well.

Given the limitations and drawbacks of the existing autonomous landing methods, it is possible to outline the properties of a \textit{robust} method: 
\begin{enumerate}
    \item The landing controller should be able to track the landing platform's pose over a wide range of relative distances and orientations. This will allow the drone to continue its landing process even if it does not approach the landing platform from a specific orientation.
    \item The landing controller should not be primarily \gls{GPS}-based, but should use some other method which allows for highly-accurate localization.
    \item Dynamic control should be applied to all controlled components of the drone's position/velocity during landing, instead of arbitrary, static values such as a constant rate of descent.
    \item At no point in the landing process should the drone blindly descend without verifying that its position relative to the landing platform is conducive to a successful landing. Landings should be halted in the event that a successful landing cannot be reasonably ensured.
    \item The landing controller must be simple, in that it only uses a minimal set of tools - preferably tools that are in common use on current drone systems. This will make integration of the landing controller into physical drone systems easier in the real world.
\end{enumerate}

The system described in this thesis is designed with the stated requirements in mind. It is targeted at the real world applications of landing a drone on a stationary platform or a moving platform such as the top of a vehicle. At a high level, the landing system is based primarily on computer vision, rather than \gls{GPS}. The landing platform is fitted with a fiducial marker (explained in Section \ref{subsection:fiducial_markers}). A gimbal-mounted camera identifies and tracks the landing platform via the fiducial marker. The landing algorithm receives the location of the fiducial marker relative to the drone and calculates target velocities which direct the drone towards the landing platform. The landing algorithm then communicates these velocities to the flight control software. From the acquisition of the landing target to contact with the landing platform, conditions of the drone are monitored in order to determine whether the landing should be aborted or not. If the landing is aborted - for example in the event that the landing target is lost, the drone loiters in a stationary position using \gls{GPS} and \gls{IMU}. Other, similar methods are described in Section \ref{section:related_work}.

More specifically, the landing system is developed in \gls{ROS} - an open source, modular robotics control framework with many existing modules. The system is built on the ArduCopter release of the wider ArduPilot code stack with the goal of minimal invasiveness. As the system will be used on a \gls{MAV}, it will use the ``common'' dialect of the MAVLink communication protocol, which is the default communication protocol within ArduPilot. The \gls{ROS} modules will be available to the open source community - links are provided in Section \ref{section:code_repositories}.