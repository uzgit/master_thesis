\label{section:real_world_testing}
% \newpage
The simulator allows for testing of the landing and gimbal controllers without consideration of logistical, environmental, and financial constraints. It is therefore ``easy'' to judge the performance of a particular system in the simulator. However, real world testing requires a significantly more conservative mindset, taking into consideration limited battery capacity and charging time, weather conditions that may hinder or bias testing, and the inevitable risk of crashing and destroying the drone either by human error or system failure. For these reasons, testing must be targeted and agile. Furthermore, priority should be given to tests which can be carried out in the absence of actual flight, in order to minimize risk and logistical efforts.

\subsection{Drone Construction and Setup}

First, the hexacopter system, laid out in Section \ref{section:hexacopter_design} must be properly constructed and tuned. The specific process of constructing the drone is outside of the scope of this project, but emphasis should be placed on ensuring all necessary component functionality and physical security of the onboard components. Special care and independent verification should be taken to ensure the proper calibration of the power sensor in order to guarantee the accuracy of the power readings used to judge the efficiency of a landing, as well as the remaining in-flight battery capacity. The drone's native velocity and position PID control systems must be well tuned to allow for highly reliable positional control, as this is the fundamental basis of the landing control system. The drone should be tested first through conventional RC flight and then through complex point-to-point flight plans. If $w_i$ and $w_{i+1}$ represent the navigational way points between which the drone is currently traveling, cross track error is the distance from the drone to the straight line between $w_i$ and $w_{i+1}$. Minimization of cross track error can improve the drone's positional control. This can be accomplished through careful tuning of the drone's attitude, velocity, and position PID control systems. All of these PID controllers should be tuned to minimize both correction time and overshoot.

\subsection{Companion Board Software Setup}

The companion boards - in this case, the Google Coral Dev and NVIDIA Jetson Nano must be loaded with Debian Mendel and Ubuntu respectively, and all necessary ROS libraries must be installed for running the landing and gimbal controllers. These modules should be installed from source and most of the dependencies should be installed using the Debian package manager. Specifics for the installation will be included in the Github repositories included in Section \ref{section:code_repositories}. Initial verification of basic functionality includes testing of both the WhyCon and April Tag fiducial systems using connected camera modules to estimate the pose of smaller, test markers from various distances. 

\subsection{Fiducial System Calibration and Initial Pose Estimation}

The gimbal must be examined closely to determine the correct method of extracting its orientation data. If it is possible to extract the yaw from the gimbal's IMU then it will be necessary to route this information to the companion board in order to enable calculation of the necessary coordinate system transforms. If the control signal for the gimbal's yaw position provides an absolute position instead of a velocity, then it is possible to use this value instead, with no extra communication overhead. It is not necessary to extract the pitch and roll values, but these could provide good information in the analysis of the gimbal controller's performance.

Once the specifics of the information flow between the gimbal and companion board have been determined, the ability of the gimbal controller to aim the gimbal at the marker should be evaluated, as in Section \ref{section:gimbal_controller_results}. This requires no in-flight operations, and can be done in a lab or other open environment. With the camera-mounted gimbal placed at a high vantage point, several positions should be measured and labeled on the floor, so that their true relative horizontal positions with respect to the camera are known with certainty. Calibration of the April Tag and WhyCon system can then take place according to the guidelines provided by each system. In the case of WhyCon this involves setting the size of the marker, and in the case of April Tag this involves setting both the size and the ID. The pose estimation capabilities of the camera can then be determined using statistical analysis. This test will inherently involve more ambient discoloration and distortion than the simulator, as the physical camera is very likely to have non-zero distortion coefficients, unlike the simulated camera module. With the gimbal controller disabled, each marker should be placed off-center in the camera's field of view. Then the gimbal controller should be enabled and suddenly center the marker in the camera frame, providing an accurate pose with relatively low pose estimation error the entire time.

\subsection{Flight Controller Integration and Initial Flights}

The communication between ArduPilot and the landing controller can be reconfigured using the MAVROS launch file. Instead of communicating with the \texttt{sim\_vehicle.py} program, MAVROS will communicate with the ArduPilot executable in the case that the system architecture involves only a single board - for example those architectures using a Navio2. In the case that the system has a flight controller board and a companion board, MAVROS will communicate with the ArduPilot executable over USB. Successful communication can be easily verified through inspection of MAVROS topics and ground control station logs which show the specific velocity set point messages that are generated by MAVROS during landing.

Before the landing controller is enabled, in-flight pose estimation tests must be carried out to evaluate the performance of the pose estimation system with real-world motion, vibration, and ambient light. The in-flight performance of the gimbal controller must also be evaluated and its PID parameters may need to be refined, especially to minimize oscillation. In this scenario, the pose estimates will need to be calculated using GPS or some other external positioning system, in the absence of ground truths provided by a simulator. This will necessarily add noise into the system and it should therefore be expected that the pose estimation will be less accurate. The drone's GPS position should be considered as a good estimate for the drone's position. However, the GPS position can be corrected through comparison of the drone's perceived position when it is at known landmarks. For example, if a landmark is at a location with accurately-determined coordinates, the drone's perceived location via GPS can be corrected using the difference between this value and the true position of the landmark. This consideration should be made for each test, as environmental conditions will change the performance of the GPS over time. The estimated coordinates of the landing pad should be compared to known coordinates of the landing pad. The difference in these positions can then be converted to a more readily usable unit such as meters within the drone's local reference frame.

\subsection{Velocity PID Controller Tuning}

The experiments in Section \ref{subsection:pid_tuning} can be adapted to suit a real-world scenario. First, tuning of the north and east velocity PID controllers should allow the drone to approach the landing pad and stop directly above it quickly, without overshooting. These tests should be done with a more conservative mindset than that used in the simulator. The parameters should be adjusted after each approach in order to conserve battery and reduce testing time. The yaw PID controller can be tuned in the same way as in the simulator, since each test is relatively quick and power-efficient. The up PID controller should be tuned similarly to the method used in the simulator as well, but with the imperative that overshoot can be fatal for the drone, in that it may cause a crash. This means that parameters should be adjusted with extreme caution, with only small increases in $k_p$ and small decreases in $k_d$. Unfortunately, the PID tuning requires a human finesse, which adds an element of uncertainty into the process. Throughout this entire process, a human operator must be ready to disable the landing controller and take control of the drone at any time, in order to protect against malfunctions, unpredictable weather conditions, and any other faults.

\subsection{Landings}

Once all of the PID controllers have been tuned, the landing controller can be tested as a whole. Stationary landing tests should take place first, as they are simpler. Then moving tests should be carried out. These tests can take much the same form as those in Sections \ref{subsection:stationary_landing_scenarios} and \ref{section:moving_landing_scenarios}, wherein the drone is first positioned so that the landing pad is not recognizable. The landing controller should be enabled manually and then the drone should be directed towards the landing platform in such a way that the landing platform will appear clearly to be recognized in the camera's field of view. Under human supervision, the landing controller should take control of the drone during approach and landing. The human supervisor should retake control in the event of any anomalies. The landings should be conducted from a variety of initial orientations and speeds. Landing performance can be evaluated based on time from landing platform recognition to touchdown, and based on energy consumption. Unfortunately, these tests will inherently be subject to wind other weather conditions, as they must be conducted outside. 